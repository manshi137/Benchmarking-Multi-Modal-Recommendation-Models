{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import librosa\n",
    "import csv\n",
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "from PIL import Image\n",
    "# import requests\n",
    "from transformers import AutoProcessor, CLIPVisionModelWithProjection\n",
    "\n",
    "# jpg_dir =  \"/Users/manshisagar/Desktop/sem-7 assign/col865/project/COL865_MMRS/ml-100k/Image\"\n",
    "# ekansh\n",
    "jpg_dir = \"/Users/manshisagar/Desktop/sem-7assign/col865/project/COL865_MMRS/movie_posters_resized\"\n",
    "\n",
    "model = CLIPVisionModelWithProjection.from_pretrained(\"openai/clip-vit-base-patch32\")\n",
    "processor = AutoProcessor.from_pretrained(\"openai/clip-vit-base-patch32\")\n",
    "\n",
    "# def resize_and_preprocess_image(image_path, target_size=(256, 256)):\n",
    "#     image = Image.open(image_path)\n",
    "#     image = image.resize(target_size)\n",
    "#     inputs = processor(images=image, return_tensors=\"pt\")\n",
    "#     return inputs\n",
    "\n",
    "image_files = [filename for filename in os.listdir(jpg_dir) if filename.lower().endswith(('.jpg', '.png', '.jpeg'))]\n",
    "print(len(image_files))\n",
    "\n",
    "\n",
    "\n",
    "arr_image_embeds= []\n",
    "\n",
    "# Loop through all the image files and process them\n",
    "for i in range(800):\n",
    "    # print(filename)\n",
    "    filename = image_files[i]\n",
    "    print(i)\n",
    "    file_path = os.path.join(jpg_dir, filename)\n",
    "    image_sample = Image.open(file_path)\n",
    "    inputs = processor(images=image_sample, return_tensors=\"pt\")\n",
    "    outputs = model(**inputs)\n",
    "    image_embeds = outputs.image_embeds\n",
    "    arr_image_embeds.append(image_embeds)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(800, len(image_files)):\n",
    "    # print(filename)\n",
    "    filename = image_files[i]\n",
    "    print(i)\n",
    "    file_path = os.path.join(jpg_dir, filename)\n",
    "    image_sample = Image.open(file_path)\n",
    "    inputs = processor(images=image_sample, return_tensors=\"pt\")\n",
    "    outputs = model(**inputs)\n",
    "    image_embeds = outputs.image_embeds\n",
    "    arr_image_embeds.append(image_embeds)\n",
    "\n",
    "# for i in range(len(image_files)):\n",
    "#     filename = image_files[i]\n",
    "#     print(i)\n",
    "#     file_path = os.path.join(jpg_dir, filename)\n",
    "#     inputs = resize_and_preprocess_image(file_path)\n",
    "#     outputs = model(**inputs)\n",
    "#     image_embeds = outputs.image_embeds\n",
    "#     arr_image_embeds.append(image_embeds)\n",
    "\n",
    "print(\"size of tensor == \", len(arr_image_embeds[0]))\n",
    "print(\"size of arr_image_embeds== \", len(arr_image_embeds))\n",
    "new_image_embeds= []\n",
    "for t in arr_image_embeds:\n",
    "    temp= t.squeeze()\n",
    "    new_image_embeds.append(temp)\n",
    "\n",
    "print(\"size of tensor == \", len(new_image_embeds[0]))\n",
    "print(\"size of new_image_embeds== \", len(new_image_embeds))\n",
    "resized_image_embeds= []\n",
    "# resizing text embeddings to 384 \n",
    "for t in new_image_embeds:\n",
    "    resized_i = torch.nn.functional.interpolate(t.unsqueeze(0).unsqueeze(0), size = (4096,), mode = 'linear').squeeze()\n",
    "    resized_image_embeds.append(resized_i)\n",
    "\n",
    "print(\"size of new tensor == \", resized_image_embeds[0].size())\n",
    "print(\"size of resized_image_embeds== \", len(resized_image_embeds))\n",
    "# saving text embeddings in text_feat.npy\n",
    "numpy_array = [tensor.detach().numpy() for tensor in resized_image_embeds]\n",
    "\n",
    "stacked_resized_text_embeds = np.stack(numpy_array, axis=0)\n",
    "\n",
    "np.save('images_feat.npy',stacked_resized_text_embeds)\n",
    "print(\"saved text embeddings in image_feat.npy\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
