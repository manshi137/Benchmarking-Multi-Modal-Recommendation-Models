{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import torch\n",
    "import numpy as np\n",
    "from transformers import BertTokenizer, BertModel\n",
    "\n",
    "file_path = 'items.csv'\n",
    "\n",
    "with open(file_path, 'r', encoding='utf-8') as file:\n",
    "    data_reader = csv.reader(file)\n",
    "    data = [row for row in data_reader]\n",
    "\n",
    "ind1 = [5, 29, 30, 31, 32]\n",
    "moviedesc = []\n",
    "for i in range(1, len(data)):\n",
    "    tmp = \"\"\n",
    "    for j in ind1:\n",
    "        tmp += data[i][j]\n",
    "        tmp += \" \"\n",
    "    # genres\n",
    "    for j in range(10, 28):\n",
    "        if data[i][j] == '1':\n",
    "            tmp += data[0][j]\n",
    "            tmp += \" \"\n",
    "    moviedesc.append(tmp)\n",
    "\n",
    "print(\"len(moviedesc): \", len(moviedesc))\n",
    "print(moviedesc)\n",
    "\n",
    "# Load pre-trained BERT model tokenizer and model\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "model = BertModel.from_pretrained('bert-base-uncased')\n",
    "\n",
    "# Tokenize the input text and convert it to tensor\n",
    "input_ids = tokenizer(moviedesc, padding=True, truncation=True, return_tensors=\"pt\")\n",
    "with torch.no_grad():\n",
    "    outputs = model(**input_ids)\n",
    "\n",
    "# print(\"output shape = \", outputs.shape)\n",
    "# Only take the output embeddings from the last layer\n",
    "last_hidden_states = outputs.last_hidden_state\n",
    "print(\"last_hidden_states shape= \", last_hidden_states)\n",
    "\n",
    "# For sentence embeddings, you can use the [CLS] token representation\n",
    "sentence_embeddings = last_hidden_states[:, 0, :]\n",
    "\n",
    "print(\"BERT Sentence Embedding Shape:\", sentence_embeddings.shape)\n",
    "print(sentence_embeddings)\n",
    "\n",
    "# # Save embeddings\n",
    "# numpy_array = sentence_embeddings.detach().numpy()\n",
    "# print(\"numpy_array shape = \", len(numpy_array))\n",
    "# np.save('text_feat.npy', numpy_array)\n",
    "# print(\"Saved text embeddings in text_feat.npy\")\n",
    "\n",
    "resized_text_embeds = []\n",
    "\n",
    "\n",
    "# resizing text embeddings to 384 \n",
    "for t in sentence_embeddings:\n",
    "    resized_t = torch.nn.functional.interpolate(t.unsqueeze(0).unsqueeze(0), size = (384,), mode = 'linear').squeeze()\n",
    "    resized_text_embeds.append(resized_t)\n",
    "\n",
    "print(\"len(resized_text_embeds): \", len(resized_text_embeds))\n",
    "# saving text embeddings in text_feat.npy\n",
    "numpy_array = [tensor.detach().numpy() for tensor in resized_text_embeds]\n",
    "print(\"len(numpy_array): \", len(numpy_array))\n",
    "stacked_resized_text_embeds = np.stack(numpy_array, axis=0)\n",
    "print(\"stacked_resized_text_embeds.shape: \", stacked_resized_text_embeds.shape)\n",
    "np.save('data/ml100k/text_feat.npy',stacked_resized_text_embeds)\n",
    "print(\"saved text embeddings in text_feat.npy\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
